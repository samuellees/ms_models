use : cuda
model network defination as following:
Xception(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (block1): Block(
    (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (skipbn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): SeparableConv2d(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): SeparableConv2d(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (block2): Block(
    (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (skipbn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (block3): Block(
    (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (skipbn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
        (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (block4): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block5): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block6): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block7): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block8): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block9): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block10): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block11): Block(
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU(inplace=True)
      (7): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (block12): Block(
    (skip): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (skipbn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (rep): Sequential(
      (0): ReLU()
      (1): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU(inplace=True)
      (4): SeparableConv2d(
        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)
        (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (conv3): SeparableConv2d(
    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (bn3): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): SeparableConv2d(
    (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)
    (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (bn4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout_last): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=2048, out_features=10, bias=True)
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 15, 15]             864
       BatchNorm2d-2           [-1, 32, 15, 15]              64
              ReLU-3           [-1, 32, 15, 15]               0
            Conv2d-4           [-1, 64, 13, 13]          18,432
       BatchNorm2d-5           [-1, 64, 13, 13]             128
              ReLU-6           [-1, 64, 13, 13]               0
            Conv2d-7           [-1, 64, 13, 13]             576
            Conv2d-8          [-1, 128, 13, 13]           8,192
   SeparableConv2d-9          [-1, 128, 13, 13]               0
      BatchNorm2d-10          [-1, 128, 13, 13]             256
             ReLU-11          [-1, 128, 13, 13]               0
             ReLU-12          [-1, 128, 13, 13]               0
           Conv2d-13          [-1, 128, 13, 13]           1,152
           Conv2d-14          [-1, 128, 13, 13]          16,384
  SeparableConv2d-15          [-1, 128, 13, 13]               0
      BatchNorm2d-16          [-1, 128, 13, 13]             256
        MaxPool2d-17            [-1, 128, 7, 7]               0
           Conv2d-18            [-1, 128, 7, 7]           8,192
      BatchNorm2d-19            [-1, 128, 7, 7]             256
            Block-20            [-1, 128, 7, 7]               0
             ReLU-21            [-1, 128, 7, 7]               0
           Conv2d-22            [-1, 128, 7, 7]           1,152
           Conv2d-23            [-1, 256, 7, 7]          32,768
  SeparableConv2d-24            [-1, 256, 7, 7]               0
      BatchNorm2d-25            [-1, 256, 7, 7]             512
             ReLU-26            [-1, 256, 7, 7]               0
             ReLU-27            [-1, 256, 7, 7]               0
           Conv2d-28            [-1, 256, 7, 7]           2,304
           Conv2d-29            [-1, 256, 7, 7]          65,536
  SeparableConv2d-30            [-1, 256, 7, 7]               0
      BatchNorm2d-31            [-1, 256, 7, 7]             512
        MaxPool2d-32            [-1, 256, 4, 4]               0
           Conv2d-33            [-1, 256, 4, 4]          32,768
      BatchNorm2d-34            [-1, 256, 4, 4]             512
            Block-35            [-1, 256, 4, 4]               0
             ReLU-36            [-1, 256, 4, 4]               0
           Conv2d-37            [-1, 256, 4, 4]           2,304
           Conv2d-38            [-1, 728, 4, 4]         186,368
  SeparableConv2d-39            [-1, 728, 4, 4]               0
      BatchNorm2d-40            [-1, 728, 4, 4]           1,456
             ReLU-41            [-1, 728, 4, 4]               0
             ReLU-42            [-1, 728, 4, 4]               0
           Conv2d-43            [-1, 728, 4, 4]           6,552
           Conv2d-44            [-1, 728, 4, 4]         529,984
  SeparableConv2d-45            [-1, 728, 4, 4]               0
      BatchNorm2d-46            [-1, 728, 4, 4]           1,456
        MaxPool2d-47            [-1, 728, 2, 2]               0
           Conv2d-48            [-1, 728, 2, 2]         186,368
      BatchNorm2d-49            [-1, 728, 2, 2]           1,456
            Block-50            [-1, 728, 2, 2]               0
             ReLU-51            [-1, 728, 2, 2]               0
           Conv2d-52            [-1, 728, 2, 2]           6,552
           Conv2d-53            [-1, 728, 2, 2]         529,984
  SeparableConv2d-54            [-1, 728, 2, 2]               0
      BatchNorm2d-55            [-1, 728, 2, 2]           1,456
             ReLU-56            [-1, 728, 2, 2]               0
             ReLU-57            [-1, 728, 2, 2]               0
           Conv2d-58            [-1, 728, 2, 2]           6,552
           Conv2d-59            [-1, 728, 2, 2]         529,984
  SeparableConv2d-60            [-1, 728, 2, 2]               0
      BatchNorm2d-61            [-1, 728, 2, 2]           1,456
             ReLU-62            [-1, 728, 2, 2]               0
             ReLU-63            [-1, 728, 2, 2]               0
           Conv2d-64            [-1, 728, 2, 2]           6,552
           Conv2d-65            [-1, 728, 2, 2]         529,984
  SeparableConv2d-66            [-1, 728, 2, 2]               0
      BatchNorm2d-67            [-1, 728, 2, 2]           1,456
            Block-68            [-1, 728, 2, 2]               0
             ReLU-69            [-1, 728, 2, 2]               0
           Conv2d-70            [-1, 728, 2, 2]           6,552
           Conv2d-71            [-1, 728, 2, 2]         529,984
  SeparableConv2d-72            [-1, 728, 2, 2]               0
      BatchNorm2d-73            [-1, 728, 2, 2]           1,456
             ReLU-74            [-1, 728, 2, 2]               0
             ReLU-75            [-1, 728, 2, 2]               0
           Conv2d-76            [-1, 728, 2, 2]           6,552
           Conv2d-77            [-1, 728, 2, 2]         529,984
  SeparableConv2d-78            [-1, 728, 2, 2]               0
      BatchNorm2d-79            [-1, 728, 2, 2]           1,456
             ReLU-80            [-1, 728, 2, 2]               0
             ReLU-81            [-1, 728, 2, 2]               0
           Conv2d-82            [-1, 728, 2, 2]           6,552
           Conv2d-83            [-1, 728, 2, 2]         529,984
  SeparableConv2d-84            [-1, 728, 2, 2]               0
      BatchNorm2d-85            [-1, 728, 2, 2]           1,456
            Block-86            [-1, 728, 2, 2]               0
             ReLU-87            [-1, 728, 2, 2]               0
           Conv2d-88            [-1, 728, 2, 2]           6,552
           Conv2d-89            [-1, 728, 2, 2]         529,984
  SeparableConv2d-90            [-1, 728, 2, 2]               0
      BatchNorm2d-91            [-1, 728, 2, 2]           1,456
             ReLU-92            [-1, 728, 2, 2]               0
             ReLU-93            [-1, 728, 2, 2]               0
           Conv2d-94            [-1, 728, 2, 2]           6,552
           Conv2d-95            [-1, 728, 2, 2]         529,984
  SeparableConv2d-96            [-1, 728, 2, 2]               0
      BatchNorm2d-97            [-1, 728, 2, 2]           1,456
             ReLU-98            [-1, 728, 2, 2]               0
             ReLU-99            [-1, 728, 2, 2]               0
          Conv2d-100            [-1, 728, 2, 2]           6,552
          Conv2d-101            [-1, 728, 2, 2]         529,984
 SeparableConv2d-102            [-1, 728, 2, 2]               0
     BatchNorm2d-103            [-1, 728, 2, 2]           1,456
           Block-104            [-1, 728, 2, 2]               0
            ReLU-105            [-1, 728, 2, 2]               0
          Conv2d-106            [-1, 728, 2, 2]           6,552
          Conv2d-107            [-1, 728, 2, 2]         529,984
 SeparableConv2d-108            [-1, 728, 2, 2]               0
     BatchNorm2d-109            [-1, 728, 2, 2]           1,456
            ReLU-110            [-1, 728, 2, 2]               0
            ReLU-111            [-1, 728, 2, 2]               0
          Conv2d-112            [-1, 728, 2, 2]           6,552
          Conv2d-113            [-1, 728, 2, 2]         529,984
 SeparableConv2d-114            [-1, 728, 2, 2]               0
     BatchNorm2d-115            [-1, 728, 2, 2]           1,456
            ReLU-116            [-1, 728, 2, 2]               0
            ReLU-117            [-1, 728, 2, 2]               0
          Conv2d-118            [-1, 728, 2, 2]           6,552
          Conv2d-119            [-1, 728, 2, 2]         529,984
 SeparableConv2d-120            [-1, 728, 2, 2]               0
     BatchNorm2d-121            [-1, 728, 2, 2]           1,456
           Block-122            [-1, 728, 2, 2]               0
            ReLU-123            [-1, 728, 2, 2]               0
          Conv2d-124            [-1, 728, 2, 2]           6,552
          Conv2d-125            [-1, 728, 2, 2]         529,984
 SeparableConv2d-126            [-1, 728, 2, 2]               0
     BatchNorm2d-127            [-1, 728, 2, 2]           1,456
            ReLU-128            [-1, 728, 2, 2]               0
            ReLU-129            [-1, 728, 2, 2]               0
          Conv2d-130            [-1, 728, 2, 2]           6,552
          Conv2d-131            [-1, 728, 2, 2]         529,984
 SeparableConv2d-132            [-1, 728, 2, 2]               0
     BatchNorm2d-133            [-1, 728, 2, 2]           1,456
            ReLU-134            [-1, 728, 2, 2]               0
            ReLU-135            [-1, 728, 2, 2]               0
          Conv2d-136            [-1, 728, 2, 2]           6,552
          Conv2d-137            [-1, 728, 2, 2]         529,984
 SeparableConv2d-138            [-1, 728, 2, 2]               0
     BatchNorm2d-139            [-1, 728, 2, 2]           1,456
           Block-140            [-1, 728, 2, 2]               0
            ReLU-141            [-1, 728, 2, 2]               0
          Conv2d-142            [-1, 728, 2, 2]           6,552
          Conv2d-143            [-1, 728, 2, 2]         529,984
 SeparableConv2d-144            [-1, 728, 2, 2]               0
     BatchNorm2d-145            [-1, 728, 2, 2]           1,456
            ReLU-146            [-1, 728, 2, 2]               0
            ReLU-147            [-1, 728, 2, 2]               0
          Conv2d-148            [-1, 728, 2, 2]           6,552
          Conv2d-149            [-1, 728, 2, 2]         529,984
 SeparableConv2d-150            [-1, 728, 2, 2]               0
     BatchNorm2d-151            [-1, 728, 2, 2]           1,456
            ReLU-152            [-1, 728, 2, 2]               0
            ReLU-153            [-1, 728, 2, 2]               0
          Conv2d-154            [-1, 728, 2, 2]           6,552
          Conv2d-155            [-1, 728, 2, 2]         529,984
 SeparableConv2d-156            [-1, 728, 2, 2]               0
     BatchNorm2d-157            [-1, 728, 2, 2]           1,456
           Block-158            [-1, 728, 2, 2]               0
            ReLU-159            [-1, 728, 2, 2]               0
          Conv2d-160            [-1, 728, 2, 2]           6,552
          Conv2d-161            [-1, 728, 2, 2]         529,984
 SeparableConv2d-162            [-1, 728, 2, 2]               0
     BatchNorm2d-163            [-1, 728, 2, 2]           1,456
            ReLU-164            [-1, 728, 2, 2]               0
            ReLU-165            [-1, 728, 2, 2]               0
          Conv2d-166            [-1, 728, 2, 2]           6,552
          Conv2d-167            [-1, 728, 2, 2]         529,984
 SeparableConv2d-168            [-1, 728, 2, 2]               0
     BatchNorm2d-169            [-1, 728, 2, 2]           1,456
            ReLU-170            [-1, 728, 2, 2]               0
            ReLU-171            [-1, 728, 2, 2]               0
          Conv2d-172            [-1, 728, 2, 2]           6,552
          Conv2d-173            [-1, 728, 2, 2]         529,984
 SeparableConv2d-174            [-1, 728, 2, 2]               0
     BatchNorm2d-175            [-1, 728, 2, 2]           1,456
           Block-176            [-1, 728, 2, 2]               0
            ReLU-177            [-1, 728, 2, 2]               0
          Conv2d-178            [-1, 728, 2, 2]           6,552
          Conv2d-179            [-1, 728, 2, 2]         529,984
 SeparableConv2d-180            [-1, 728, 2, 2]               0
     BatchNorm2d-181            [-1, 728, 2, 2]           1,456
            ReLU-182            [-1, 728, 2, 2]               0
            ReLU-183            [-1, 728, 2, 2]               0
          Conv2d-184            [-1, 728, 2, 2]           6,552
          Conv2d-185            [-1, 728, 2, 2]         529,984
 SeparableConv2d-186            [-1, 728, 2, 2]               0
     BatchNorm2d-187            [-1, 728, 2, 2]           1,456
            ReLU-188            [-1, 728, 2, 2]               0
            ReLU-189            [-1, 728, 2, 2]               0
          Conv2d-190            [-1, 728, 2, 2]           6,552
          Conv2d-191            [-1, 728, 2, 2]         529,984
 SeparableConv2d-192            [-1, 728, 2, 2]               0
     BatchNorm2d-193            [-1, 728, 2, 2]           1,456
           Block-194            [-1, 728, 2, 2]               0
            ReLU-195            [-1, 728, 2, 2]               0
          Conv2d-196            [-1, 728, 2, 2]           6,552
          Conv2d-197            [-1, 728, 2, 2]         529,984
 SeparableConv2d-198            [-1, 728, 2, 2]               0
     BatchNorm2d-199            [-1, 728, 2, 2]           1,456
            ReLU-200            [-1, 728, 2, 2]               0
            ReLU-201            [-1, 728, 2, 2]               0
          Conv2d-202            [-1, 728, 2, 2]           6,552
          Conv2d-203           [-1, 1024, 2, 2]         745,472
 SeparableConv2d-204           [-1, 1024, 2, 2]               0
     BatchNorm2d-205           [-1, 1024, 2, 2]           2,048
       MaxPool2d-206           [-1, 1024, 1, 1]               0
          Conv2d-207           [-1, 1024, 1, 1]         745,472
     BatchNorm2d-208           [-1, 1024, 1, 1]           2,048
           Block-209           [-1, 1024, 1, 1]               0
          Conv2d-210           [-1, 1024, 1, 1]           9,216
          Conv2d-211           [-1, 1536, 1, 1]       1,572,864
 SeparableConv2d-212           [-1, 1536, 1, 1]               0
     BatchNorm2d-213           [-1, 1536, 1, 1]           3,072
            ReLU-214           [-1, 1536, 1, 1]               0
          Conv2d-215           [-1, 1536, 1, 1]          13,824
          Conv2d-216           [-1, 2048, 1, 1]       3,145,728
 SeparableConv2d-217           [-1, 2048, 1, 1]               0
     BatchNorm2d-218           [-1, 2048, 1, 1]           4,096
            ReLU-219           [-1, 2048, 1, 1]               0
          Linear-220                   [-1, 10]          20,490
================================================================
Total params: 20,827,442
Trainable params: 20,827,442
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 7.84
Params size (MB): 79.45
Estimated Total Size (MB): 87.30
----------------------------------------------------------------
[ 0/50]: slurmstepd: error: *** JOB 7229492 ON gpu01 CANCELLED AT 2020-07-31T11:56:53 ***
